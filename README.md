# Data Engineer

## SUMMARY
-	Experienced Data Engineer with 4+ years of expertise in building scalable data pipelines, optimizing ETL workflows, and leveraging cloud platforms like AWS and Snowflake, combined with strong technical expertise, business acumen, and communication skills to drive high-impact business outcomes
-	Well versed with Agile with Waterfall Model, and Test-driven Development (TDD) methodologies. 
-	Adept in statistical programming languages like Python, and Apache Spark including Big Data technologies like Hadoop.
-	Skilled in data warehousing with Amazon Redshift, Snowflake, and orchestrating data pipelines using Apache Airflow.  
-	Experience in Data Integration and Data Warehousing using various ETL tools Informatica Power Center, SSIS, Talend.  
-	Expert in Tableau, Power BI, and SSRS to create interactive data visualizations that drive data-driven decision-making.  
-	Extensive experience working with RDBMS such as SQL Server, MySQL, and NoSQL databases such as MongoDB.

## SKILLS
- **Languages:** Python, R, SQL, JavaScript, SAS  
- **Packages:** NumPy, Pandas, Matplotlib, SciPy, Scikit-learn, SQLALchemy, TensorFlow 
- **Database:** SQL Server, MySQL, PostgreSQL, Oracle, Mongo DB
- **Cloud and Big Data:** AWS (S3, Lambda, Glue), Azure (Databricks, Data factory, Data Lake), Apache (Kafka, NiFi, Airflow)
- **Other Tools:** Git, MS Excel, AWS, Tableau, Informatica, Minitab, RPA UiPath, Power BI, Snowflake, Palisade decision tools 


## EXPERIENCE
### Data Engineer                                                                                                                                               
#### Berkshire Hathaway | Jan 2024 – Present | MA, USA
-	Automated data pipelines using Apache Airflow, improving system reliability and reducing manual intervention by 40%.
-	Worked with other stakeholders to obtain requirements, develop data models, and improve data processing efficiency, cutting processing time in half.
-	Integrated CI/CD pipelines using Jenkins and GitLab CI/CD to streamline deployment and reduce development cycle times.
-	Integrated AWS services like S3 and Redshift to create and manage the cloud data environment, achieving a 30% improvement in data ingestion and storage.
-	Used NoSQL databases such as MongoDB and DynamoDB to store and access a large amount of semi-structured data.
-	Designed and managed ETL processes to handle 10TB of data weekly, ensuring seamless integration from multiple data sources and achieving 99.9% data accuracy.


### Data Engineer
#### Hexaware Technologies | May 2019 – July 2022 | MH, India
-	Assisted in developing ETL workflows using SSIS and Talend to extract, transform, and load data from various sources.
- Developed over 50 dashboards using Tableau and Power BI, enabling stakeholders to track KPIs and uncover insights, leading to a 15% increase in operational efficiency.
- Supported data migration by consolidating legacy systems into modern cloud-based solutions, ensuring minimal downtime.
- Optimized SQL queries and redesigned database structures, reducing query execution time by 20% and improving application response time for end-users.
- Conducted data quality checks, debugging, and problem-solving to maintain high data quality and credibility.
- Monitored system performance with Apache Kafka, ensuring 99.92% system uptime through fault-tolerant strategies.
- Developed automated monitoring and alerting systems for data workflows, ensuring early detection and resolution of pipeline failures and data anomalies reducing downtime by 40% and maintaining 99% data integrity.
- Worked with data scientists and analysts to deliver well-formatted, well-organized and easily retrievable data for insights.

## EDUCATION
- Master’s in Business Analytics | University of Michigan, Dearborn, USA, Aug 2022 – Apr 2024
- Bachelors in Computer Science | Bennett University, Delhi, India, Aug 2016 – Jun 2020 
