# Data Engineer

## SUMMARY
•	Experienced Data Engineer with 4+ years of expertise in building scalable data pipelines, optimizing ETL workflows, and leveraging cloud platforms like AWS and Snowflake, combined with strong technical expertise, business acumen, and communication skills to drive high-impact business outcomes
•	Well versed with Agile with Waterfall Model, and Test-driven Development (TDD) methodologies.  
•	Adept in statistical programming languages like Python, and Apache Spark including Big Data technologies like Hadoop.
•	Skilled in data warehousing with Amazon Redshift, Snowflake, and orchestrating data pipelines using Apache Airflow.  
•	Experience in Data Integration and Data Warehousing using various ETL tools Informatica Power Center, SSIS, Talend.  
•	Expert in Tableau, Power BI, and SSRS to create interactive data visualizations that drive data-driven decision-making.  
•	Extensive experience working with RDBMS such as SQL Server, MySQL, and NoSQL databases such as MongoDB.

## SKILLS
**Methodologies:** SDLC, Agile, Waterfall 
**Language:** Python, R, SQL, SAS 
**ML Algorithm:** Linear Regression, Logistic Regression, Decision Trees, Supervised Learning, Unsupervised Learning, Classification, SVM, Random Forests, Naive Bayes, KNN, K Means 
**Packages:** NumPy, Pandas, Matplotlib, SciPy, Scikit-learn, TensorFlow 
**Visualization Tools:** Tableau, Power BI 
**Database:** SQL Server, MySQL, PostgreSQL, Oracle, Mongo DB
**Cloud and Big Data:** AWS (S3, Lambda, Glue), Azure (Databricks, Data factory, Data Lake), Apache (Kafka, NiFi, Airflow)
**Other Tools:** Git, MS Excel, AWS 
**Operating System:** Windows, Linux 

## EXPERIENCE
### Data Engineer                                                                                                                                               
#### Berkshire Hathaway | Jan 2024 – Present | USA
•	Automated data pipelines using Apache Airflow, improving system reliability and reducing manual intervention by 40%.
•	Worked with other stakeholders to obtain requirements, develop data models, and improve data processing efficiency, cutting processing time in half.
•	Integrated CI/CD pipelines using Jenkins and GitLab CI/CD to streamline deployment and reduce development cycle times.
•	Integrated AWS services like S3 and Redshift to create and manage the cloud data environment, achieving a 30% improvement in data ingestion and storage.
•	Used NoSQL databases such as MongoDB and DynamoDB to store and access a large amount of semi-structured data.
•	Built and maintained large-scale ETL processes to extract, transform, and load data from various sources into a data mart.

### Data Engineer
#### Hexaware Technologies | May 2019 – July 2022 | Pune, India
•	Assisted in developing ETL workflows using SSIS and Talend to extract, transform, and load data from various sources.
•	Developed automated monitoring and alerting systems for data workflows, ensuring early detection and resolution of pipeline failures and data anomalies.
•	Built data visualizations using Tableau and Power BI, empowering business stakeholders with actionable insights.
•	Supported data migration by consolidating legacy systems into modern cloud-based solutions, ensuring minimal downtime.
•	Optimized SQL queries and database structures to improve data retrieval performance, achieving a 20% reduction in query execution time.
•	Conducted data quality checks, debugging, and problem-solving to maintain high data quality and credibility.
•	Monitored system performance with Apache Kafka and implemented strategies for high availability and fault tolerance.
•	Worked with data scientists and analysts to deliver well-formatted, well-organized and easily retrievable data for insights.

## EDUCATION
- Master’s in Business Analytics | University of Michigan, Dearborn, USA, Aug 2022 – Apr 2024
- Bachelors in Computer Science Engineering | Bennett University, Delhi, India, Aug 2016 – Jun 2020 
