# Data Engineer

## SUMMARY
-	Experienced Data Engineer with 4+ years of expertise in building scalable data pipelines, optimizing ETL workflows, and leveraging cloud platforms like AWS and Snowflake, combined with strong technical expertise, business acumen, and communication skills to drive high-impact business outcomes
-	Well versed with Agile with Waterfall Model, and Test-driven Development (TDD) methodologies. 
-	Adept in statistical programming languages like Python, and Apache Spark including Big Data technologies like Hadoop.
-	Skilled in data warehousing with Amazon Redshift, Snowflake, and orchestrating data pipelines using Apache Airflow.  
-	Experience in Data Integration and Data Warehousing using various ETL tools Informatica Power Center, SSIS, Talend.  
-	Expert in Tableau, Power BI, and SSRS to create interactive data visualizations that drive data-driven decision-making.  
-	Extensive experience working with RDBMS such as SQL Server, MySQL, and NoSQL databases such as MongoDB.

## SKILLS
- **Languages:** Python, R, SQL, JavaScript, SAS  
- **Packages:** NumPy, Pandas, Matplotlib, SciPy, Scikit-learn, SQLALchemy, TensorFlow 
- **Database:** SQL Server, MySQL, PostgreSQL, Oracle, Mongo DB
- **Cloud and Big Data:** AWS (S3, Lambda, Glue), Azure (Databricks, Data factory, Data Lake), Apache (Kafka, NiFi, Airflow)
- **Other Tools:** Git, MS Excel, AWS, Tableau, Informatica, Minitab, RPA UiPath, Power BI, Snowflake, Palisade decision tools 


## EXPERIENCE
### Data Engineer                                                                                                                                               
#### Berkshire Hathaway | Jan 2024 – Present | MA, USA
-	Automated data pipelines using Apache Airflow, improving system reliability and reducing manual intervention by 40%.
-	Worked with other stakeholders to obtain requirements, develop data models, and improve data processing efficiency, cutting processing time in half.
-	Integrated CI/CD pipelines using Jenkins and GitLab CI/CD to streamline deployment and reduce development cycle times.
-	Integrated AWS services like S3 and Redshift to create and manage the cloud data environment, achieving a 30% improvement in data ingestion and storage.
-	Used NoSQL databases such as MongoDB and DynamoDB to store and access a large amount of semi-structured data.
-	Designed and managed ETL processes to handle 10TB of data weekly, ensuring seamless integration from multiple data sources and achieving 99.9% data accuracy.


### Data Engineer
#### Hexaware Technologies | May 2019 – July 2022 | MH, India
-	Assisted in developing ETL workflows using SSIS and Talend to extract, transform, and load data from various sources.
- Developed over 50 dashboards using Tableau and Power BI, enabling stakeholders to track KPIs and uncover insights, leading to a 15% increase in operational efficiency.
- Supported data migration by consolidating legacy systems into modern cloud-based solutions, ensuring minimal downtime.
- Optimized SQL queries and redesigned database structures, reducing query execution time by 20% and improving application response time for end-users.
- Conducted data quality checks, debugging, and problem-solving to maintain high data quality and credibility.
- Monitored system performance with Apache Kafka, ensuring 99.92% system uptime through fault-tolerant strategies.
- Developed automated monitoring and alerting systems for data workflows, ensuring early detection and resolution of pipeline failures and data anomalies reducing downtime by 40% and maintaining 99% data integrity.
- Worked with data scientists and analysts to deliver well-formatted, well-organized and easily retrievable data for insights.

## PROJECTS
### Flint Water Line Replacement [Link](https://github.com/ravilakkakula/Flint-water-line-replacement)
- Contributed to data collection, cleaning, and processing for the Flint Water Line Replacement project. Performed exploratory data analysis to identify key factors related to lead service lines and suggest water board measures to reduce capital spent.
- Developed and evaluated machine learning models, including logistic regression, random forest, and neural networks, achieving 94% accuracy with the Bootstrap Forest based on ROC AUC scores.

### Portfolio Management
- Managed a $1,000,000 virtual stock portfolio on Stock Trak as part of an academic project from Sep 2023 to Dec 2023, outperforming the market return with a return of 16%. Some of the best trades are Amazon, Nvidia, Microsoft, Meta, Mara.
- Conducted risk assessment and diversification strategies to minimize potential losses and maximize returns, leveraging financial models and market analysis tools

### Speed Check [Link](https://github.com/ravilakkakula/Speed-check)
- Engineered a machine learning-based speed detection system using computer vision to identify and record vehicle speeds in real-time. The system accurately processes video footage to detect speeding violations and generate tickets.
- Utilized Python and OpenCV to analyze video streams from a speed trap camera, integrating speed estimation algorithms to report vehicle speeds. Achieved 88% accuracy with the Edge Impulse model

### Delta Warehousing LLC
- As part of the Decision Analysis project, we have come up with a model which helped Delta warehousing business to consider whether to install solar panels or not. [Website Link](https://sites.google.com/umich.edu/ds631-2023-fall-team-delta/home)

## EDUCATION
- Master’s in Business Analytics | University of Michigan, Dearborn, USA, Aug 2022 – Apr 2024
- Bachelors in Computer Science  | Bennett University,     Delhi, India,  Aug 2016 – Jun 2020

## CERTIFICATIONS
- AWS Certified Data Analytics – Specialty
- Snowflake Advanced Architect Certification
- Tableau Desktop Specialist
- Advanced Data Science Bootcamp

